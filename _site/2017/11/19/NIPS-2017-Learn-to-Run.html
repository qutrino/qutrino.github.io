<!DOCTYPE html>
<html lang="en">

  <head>

    <!-- Non social metatags -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="theme-color" content="#157878">

    

    <title>NIPS 2017:Learn to Run 참가기</title>

    
      <!-- Update your html tag to include the itemscope and itemtype attributes. -->
<html itemscope itemtype="http://schema.org/Article">












<!-- Place this data between the <head> tags of your website -->

  <meta name="author" content="Taeil Hur">

<meta name="description" content="" />





<!-- Schema.org markup for Google+ -->
<meta itemprop="name" content="NIPS 2017:Learn to Run 참가기">
<meta itemprop="description" content="">

  <meta itemprop="image" content="http://localhost:4000/thumbnail-jumbo.png">


<!-- Twitter Card data -->
<meta name="twitter:card" content="summary_large_image">



<meta name="twitter:title" content="NIPS 2017:Learn to Run 참가기">
<meta name="twitter:description" content="">



<!-- Twitter summary card with large image must be at least 280x150px -->

  <meta name="twitter:image:src" content="http://localhost:4000/thumbnail-jumbo.png">
  <meta property="twitter:image" content="http://localhost:4000/thumbnail-jumbo.png">

<meta property="twitter:url" content="http://localhost:4000/2017/11/19/NIPS-2017-Learn-to-Run.html">

<!-- Open Graph data -->
<meta property="og:title" content="NIPS 2017:Learn to Run 참가기" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:4000/2017/11/19/NIPS-2017-Learn-to-Run.html" />

  <meta property="og:image" content="http://localhost:4000/thumbnail-jumbo.png" />

<meta property="og:description" content="" />
<meta property="og:site_name" content="Deep Challenge" />

  <meta property="article:published_time" content="2017-11-19T00:00:00+09:00" />






  <meta property="fb:app_id" content="1798910940422432">









  





  




    

    <link rel="canonical" href="http://localhost:4000/2017/11/19/NIPS-2017-Learn-to-Run.html">

    

    <link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
    <meta name="robots" content="noarchive">

    <!-- <link rel="alternate" media="only screen and (max-width: 640px)" href="">
    <link rel="alternate" media="handheld" href=""> -->


    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="/assets/css/style.css?v=">
  </head>
  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">
    
    

    
      <a class="site-title" href="/">Deep Challenge</a>
    

    
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
          
            
            
              
              
            
          
            
            
              
                <a class="page-link" href="/about.html">About</a>
              
            
          
            
            
              
                <a class="page-link" href="/contact.html">Contact</a>
              
            
          
            
            
          
            
            
          
        </div>
      </nav>
    
  </div>
</header>


    
    
    

    <section class="page-header">
      <h1 class="project-name">NIPS 2017:Learn to Run 참가기</h1>
      <h2 class="project-tagline"></h2>
      
      <!-- Post tagline -->
      
        <h2 class="project-date">
        <time datetime="2017-11-19T00:00:00+09:00" itemprop="datePublished">
          
          Nov 19, 2017
        </time>
        
        
          • <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Taeil Hur</span></span>
        
        </h2>
      
      <!-- End: Post tagline -->
    </section>

    <section class="main-content">

      <article itemscope itemtype="http://schema.org/BlogPosting">

  <!-- <header class="post-header">
    <h1 class="post-title" itemprop="name headline">NIPS 2017:Learn to Run 참가기</h1>
    <p class="post-meta">
      <time datetime="2017-11-19T00:00:00+09:00" itemprop="datePublished">
        
        Nov 19, 2017
      </time>
      </p>
  </header> -->

  <div itemprop="articleBody">
    <p><img src="https://dnczkxd1gcfu5.cloudfront.net/images/challenges/image_file/8/8.Screen_Shot_2017-04-10_at_1.23.56_PM.png" alt="test" height="30%" width="30%" /></p>

<p><em>딥러닝 및 강화학습에 친해지고자 <a href="https://nips.cc/Conferences/2017/CompetitionTrack">NIPS 2017 Competition Track</a> 중의 하나인  <a href="https://www.crowdai.org/challenges/nips-2017-learning-to-run">NIPS 2017: Learn to Run</a>에 도전해 보았습니다. 처음 참여해본 IT분야의 competition이라 부족한 점이 많기도 하지만, 과정을 공유하여 새롭게 도전하시는 분들께 도움이 되었으면 합니다.</em></p>

<h1 id="nips-2017learn-to-run">NIPS 2017:Learn to Run</h1>

<h3 id="개요">개요</h3>
<p><em><a href="http://opensim.stanford.edu/">opensim</a>이라는 인체 시뮬레이터를 기반으로, 인체의 근육자극을 조절하여 장애물을 넘으면서 달리게 만드는것이 목표인 대회입니다. 주최측에서 openai gym과 유사한 강화학습 환경 osim-rl을 제공하였으며, 그 환경의 구체적인 정의는 아래와 같습니다.</em></p>
<ul>
  <li>Reward : x축 방향으로 골반이 이동한 거리 - 인대 힘(ligament force)의 사용량</li>
  <li>Observation: 신체 각부위의 x, y좌표 및 속도, 각속도, 다음 장애물의 위치정보: 총합 41 차원</li>
  <li>Action: 근육자극 정도. (18차원)</li>
</ul>

<h3 id="대회-기간-및-참가팀">대회 기간 및 참가팀</h3>
<ul>
  <li>1차 라운드: 2017.06.24 ~ 2017.11.05</li>
  <li>2차(최종)라운드: 2017.11.05 ~ 2017.11.13</li>
  <li>참가팀: 584팀</li>
</ul>

<h3 id="기타-규칙">기타 규칙</h3>
<ul>
  <li>높이 0.65m 이하로 골반이 내려가면 에피소드가 끝남.</li>
  <li>1000 time step(= 10초)가 지나면 에피소드가 끝남.</li>
  <li>1라운드에서는 3개의 장애물로 평가하고, 3회 시도의 평균을 취하며, 매일 5번의 submission 기회가 있음.</li>
  <li>2라운드에서는 10개의 장애물이 있는 환경에서 평가하고, 10회 시도의 평균을 취하며, 딱 5번의 submission 기회가 있음.</li>
  <li>1라운드에서의 기록이 15m이상인 팀만이 2라운드로 진출</li>
</ul>

<h1 id="최종-참가-결과">최종 참가 결과</h1>
<ul>
  <li><a href="https://www.crowdai.org/challenges/nips-2017-learning-to-run/leaderboards?challenge_round_id=1">1라운드</a>: 28위 ( 3회 평균 28.14m )</li>
  <li><a href="https://www.crowdai.org/challenges/nips-2017-learning-to-run/leaderboards">2라운드(최종)</a>: 19위 (10회 평균 24.80m )</li>
  <li>아래는 2라운드 5번의 submission 기회 중 첫번째 submission의 로컬 시뮬레이션 결과임. 실제로 평가된 시뮬레이션 영상들은 NIPS 2017 conference와 함께 공개될 예정이라고 함.</li>
</ul>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />

<video autoplay="autoplay" loop="loop" controls="controls" width="798" height="209">
  <source src="/assets/video/nips_submit_1.mp4" type="video/mp4" />
</video>

<h1 id="참가-동기-및-시기">참가 동기 및 시기</h1>
<ul>
  <li>딥러닝의 전반적인 내용 및 강화학습을 스터디하던 중, 이 competition을 뒤늦게 알게 되어, 강화학습 분야의 깊은(?) 이해를 위하여 참여 결정.</li>
  <li>1라운드 마감시한이 3~40일 정도 남은 상황에서 실질적인 참여를 시작하게 되었음.</li>
</ul>

<h1 id="초기-접근-방향">초기 접근 방향</h1>

<ul>
  <li>강화학습에 대한 교과서적인 지식밖에 없었으므로, 공식페이지의 문서 및 예제코드 습득.</li>
  <li>늦은 출발을 만회하기 위하여, 공식 페이지의 discussion channel, 공식 github repo의 issue, gitter 대화내용 등은 대부분 읽음.</li>
  <li>
    <p>참가자 중 상위 랭커 중 한명인 <a href="https://github.com/ctmakro">Qin Yongliang</a>가 자신의 모형 및 <a href="https://github.com/ctmakro/stanford-osrl">코드</a>를 공개해 놓고 있는 상황이라 아주 큰 참고가 되었음.</p>
  </li>
  <li>그나마 이 문제와 가장 비슷하다고 할 수 있는 <a href="http://www.mujoco.org/">mujuco</a>-humanoid 의 결과를 위주로 논문 서베이.</li>
  <li>적용 알고리즘을 고르기 위하여 <a href="https://gym.openai.com/envs/Humanoid-v1/">https://gym.openai.com/envs/Humanoid-v1/</a> 등의 공개된 정보 습득</li>
</ul>

<h1 id="문제해결">문제해결</h1>
<h2 id="적용-알고리즘-결정">적용 알고리즘 결정</h2>
<ul>
  <li>continuous action에 쓰이는 RL 알고리즘 중, DDPG 알고리즘 정도까지밖에 스터디를 못한 상황이었고, 논문 서베이를 해봐도 최근의 알고리즘 A3C, TRPO 등이 DDPG알고리즘을 압도하는 상황은 아닌것으로 보여서, DDPG로 먼저 시작하기로 결정.</li>
  <li><a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow">https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow</a>의 코드를 기본으로 하여 수정.</li>
</ul>

<h2 id="느린-시뮬레이션-환경">느린 시뮬레이션 환경</h2>
<ul>
  <li>실제 세상에서의 10ms에 해당하는 1 timestep을 계산하는데, 5초가 넘게 걸릴때도 있을 정도로 느린 env 시뮬레이션 환경이기 때문에 시뮬레이션 환경의 병렬화가 꼭 필요한 상황이었음. 시뮬레이션이 항상 느린것은 아니고, 근육에 부하가 많이 걸린다거나 장애물과 컨택한다거나 하는 상황에서 많은 시간이 걸렸음.</li>
  <li>
    <p>이전에 잠깐 MPI(Message Passing Interface)를 사용해본적이 있고, 최근 openai baseline 코드에서도 mpi4py를 사용한 구현을 
본적이 있어서, mpi4py를 이용한 시뮬레이션 병렬화를 구현하였음.</p>

    <table>
      <thead>
        <tr>
          <th style="text-align: left">MPI rank</th>
          <th style="text-align: left">서버</th>
          <th style="text-align: left">기능</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="text-align: left">0</td>
          <td style="text-align: left">로컬 PC</td>
          <td style="text-align: left">모델 구현 및 러닝, 다른 노드에  action값을 돌려주고 simulation 결과를 얻어서 이용함.</td>
        </tr>
        <tr>
          <td style="text-align: left">1</td>
          <td style="text-align: left">로컬 PC</td>
          <td style="text-align: left">env simul. 화면에 표시되게 하여 모니터링 용도도 겸함.</td>
        </tr>
        <tr>
          <td style="text-align: left">2  ~ 최대 200</td>
          <td style="text-align: left">5~8개의 aws c4.8xlarge 서버</td>
          <td style="text-align: left">env simul. without visualization</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>로컬PC와 aws머신을 동시에 이용하여 학습하였기 때문에, 네트워크 속도를 고려하여 한국 region의 서버를 이용.</li>
  <li>초반에는 8대의 c4.8xlarge(시간당 1.8달러, 18core, 36 hyper-thread core)를 사용하다, 2라운드에서는 비용의 부담을 느껴 5대의 c4.8xlarge 서버를 사용하였음.</li>
  <li>2,000달러이상의 aws 서비스요금 결제 예정임. ㅠ</li>
</ul>

<h2 id="preprocessing-of-observation">Preprocessing of observation</h2>
<ul>
  <li>앞서 언급한 <a href="https://github.com/ctmakro">Qin Yongliang</a>의 글과 코드를 많이 참조하였음.</li>
  <li>observation은 신체부위의 위치 및 속도, 각속도, 다음 장애물의 위치 등을 포함하여, 41차원의 vector.</li>
  <li>장애물의 위치만 빼고 다 절대좌표이기 때문에, x방향은 골반을 중심으로 한 상대좌표로 <strong>치환</strong>하였고, y방향은 골반을 중심으로 한 상대좌표를 <strong>추가</strong>하였음.</li>
  <li>속도 정보가 들어오지 않는 신체 부위는 이전 정보를 이용하여 속도 계산하여 추가하였음. (가속도는 추가하지 않음.)</li>
  <li>장애물의 경우, 자기 앞에 있는 하나의 장애물 정보만 들어오기 때문에, 아직 연관이 있는 이전 장애물 정보와 새로운 장애물 정보를 둘다 유지하도록 함.</li>
</ul>

<h2 id="hyperparameter-및-network-수정">Hyperparameter 및 network 수정</h2>

<ul>
  <li>actor learning rate, critic learning rate, reward discount, network update rate tau
    <ul>
      <li>병렬화를 감안하여도 시뮬레이션 환경이 빠른 편이 아니었기 때문에, 하이퍼 파라미터를 하나씩 바꿔보면서 나아지는 방형으로 조금씩 수정하였음.</li>
    </ul>
  </li>
  <li>noise
    <ul>
      <li>여러가지 시도를 해보다, Ornstein Uhlenbeck Process를 사용하게 되었고, 노이즈 크기를 바꾸는 수정을 가장 많이 하였음.</li>
      <li>Ornstein Uhlenbeck Process 처럼 트렌드가 있는 노이즈를 써야 효과적인 경우가 있다는것을 알게됨.</li>
    </ul>
  </li>
  <li>network
    <ul>
      <li>간단한 network에서 점점 레이어를 늘려나감. 많은 변화를 주지는 못하였음.</li>
    </ul>
  </li>
</ul>

<h2 id="코드">코드</h2>
<p><a href="https://github.com/qutrino/nips-2017-learn-to-run">https://github.com/qutrino/nips-2017-learn-to-run</a></p>

<h1 id="학습과정-및-결과제출">학습과정 및 결과제출</h1>

<ul>
  <li>초반 몇 발자국(~7m)을 걷게 만드는 세팅을 만드는 부분이 제일 힘들었음. DDPG 코드의 자잘한 버그를 고치고, 노이즈 프로세스 및 크기를 수없이 조절한 후에야 돌아가는 세팅을 찾게 됨.</li>
  <li>위의 파라미터 및 네트워크 변경의 결과로 약 15,000 episode정도에 35~39m를 달리는 최고 기록은 나왔으나, 1/3정도는 중간에 넘어졌기 때문에 30m대의 평균기록은 얻지 못하였음. 학습시간을 더 길게 해도 기록이 나아지지 않고 나빠지는 상태가 이어짐.</li>
  <li>학습 중간에 주기적으로 weight를 저장하여, 그 저장된 weight를 가지고, noise가 없는 환경에서 테스트 후 가장 좋은 결과를 준 5개를 submission하였음.(2라운드)</li>
  <li><a href="https://www.crowdai.org/challenges/nips-2017-learning-to-run/leaderboards">2라운드 평가결과</a> 10회 평균 24.80m로 19위의 성적을 기록함.</li>
  <li>1위의 경우 45.97m라는 엄청난 기록을 냄.</li>
</ul>

<h1 id="그-밖의-시도">그 밖의 시도</h1>
<ul>
  <li>batch norm. 은 시도해 보지않음. (RL에서 잘 된다는 보고가 많지 않아서.)</li>
  <li>layer norm. 을 적용해 보았으나, 좋은 결과를 얻지 못했음</li>
  <li><a href="https://arxiv.org/abs/1511.05952">Prioritized Experience Replay</a>,  openai baseline code를 이용하여 적용해 보았으나, 좋은 결과를 얻지 못했음. 리플레이 메모리가 크다보니 prioritized experience replay 의 실행 시간이 너무 많이 걸림.</li>
</ul>

<h1 id="감상">감상</h1>
<p><em>시간적으로도 여유가 많지 않은 상태였고, 병렬머신 자원을 맘편하게 쓸수 있는 환경도 아니라, 여러가지 시도를 못 해본게 아쉬움으로 남습니다. TRPO나 PPO등의 새로운 알고리즘을 사용하여 큰 변화를 주고 싶은 생각도 있었지만, 공부할 여유가 없었기도 하고, 또 수많은 하이퍼 파라미터들을 탐색할 엄두가 나지 않아 실행해보지 못하였습니다. 하지만 처음 참가한 competition이기에 무척 흥미로왔고, 배운점도 많은것 같습니다.</em></p>

<h1 id="학습과정-동영상">학습과정 동영상</h1>
<p><em>1 ~ 4000 에피소드까지의 학습과정입니다. 91명이 동시에 연습중인데 그 중 한명만을 보여주는 화면이라 학습이 빨라 보입니다.</em></p>

<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />

<video autoplay="autoplay" loop="loop" controls="controls" width="574" height="255">
  <source src="/assets/video/nips_learn.mp4" type="video/mp4" />
</video>


  </div>

  
</article>


      <footer class="site-footer">
        <!-- SVG icons from https://iconmonstr.com -->

        <!-- Github icon -->
        <span class="my-span-icon">
          <a href="" aria-label="'s GitHub" title="'s GitHub">
            <svg class="my-svg-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
          </a>
        </span>

        <!-- Twitter icon -->
        <span class="my-span-icon">
          <a href="https://twitter.com/" aria-label="'s Twitter" title="'s Twitter">
            <svg class="my-svg-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M12 0c-6.627 0-12 5.373-12 12s5.373 12 12 12 12-5.373 12-12-5.373-12-12-12zm6.066 9.645c.183 4.04-2.83 8.544-8.164 8.544-1.622 0-3.131-.476-4.402-1.291 1.524.18 3.045-.244 4.252-1.189-1.256-.023-2.317-.854-2.684-1.995.451.086.895.061 1.298-.049-1.381-.278-2.335-1.522-2.304-2.853.388.215.83.344 1.301.359-1.279-.855-1.641-2.544-.889-3.835 1.416 1.738 3.533 2.881 5.92 3.001-.419-1.796.944-3.527 2.799-3.527.825 0 1.572.349 2.096.907.654-.128 1.27-.368 1.824-.697-.215.671-.67 1.233-1.263 1.589.581-.07 1.135-.224 1.649-.453-.384.578-.87 1.084-1.433 1.489z"/></svg>
          </a>
        </span>

        <!-- RSS icon -->
        
        <!-- Contact icon -->
        
        
          <span class="my-span-icon">
            <a href="/about.html" aria-label="Contact" title="Contact ">
              <svg class="my-svg-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M12 .02c-6.627 0-12 5.373-12 12s5.373 12 12 12 12-5.373 12-12-5.373-12-12-12zm6.99 6.98l-6.99 5.666-6.991-5.666h13.981zm.01 10h-14v-8.505l7 5.673 7-5.672v8.504z"/></svg>
            </a>
          </span>
        

      </footer>
    </section>

    
  </body>
</html>
